{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1) In a group of 50 marbles, 15 are clear and the remaining 35 has either red, blue or both. a) If 20 are red and 25 are blue, how many are red and blue?\n",
    "\n",
    "What is the probability of drawing; b) a red marble, c) a blue marble and d) a red and blue marble, e) red OR blue or multi-coloured marble at random from a bag?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.285714285714\n",
      "0.357142857143\n",
      "0.142857142857\n",
      "0.785714285714\n"
     ]
    }
   ],
   "source": [
    "#Sampling probability\n",
    "\n",
    "#red = (20-x)\n",
    "#blue = (25-x)\n",
    "#35 = x+red+blue\n",
    "x = 10\n",
    "\n",
    "t = 15.+10.+20.+25.\n",
    "p_red = 20./t\n",
    "print p_red\n",
    "p_blue = 25./t\n",
    "print p_blue\n",
    "p_both = 10./t\n",
    "print p_both\n",
    "p_both = 55./t\n",
    "print p_both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A1a) 10, b) 0.29, c) 0.36, d) 0.14, e) 0.79"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2) The S2DS 2016 cohort contained 90 people. The ages are distributed normally and have a mean age of 30 with a standard devation of 5. \n",
    "\n",
    "A student is selected at random. What is the probability that \n",
    "\n",
    "a) their age is greater than 35.\n",
    "\n",
    "b) their age is less than 22.\n",
    "\n",
    "c) thier age is between 22 and 35. \n",
    "\n",
    "d) Approximately how many students are older than 35?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1587 0.0548 0.7865 14.283\n"
     ]
    }
   ],
   "source": [
    "#Normal distributions\n",
    "\n",
    "(35.-30.)/5.\n",
    "z_1 = .8413\n",
    "p_35 = 1-z_1\n",
    "(22.-30.)/5.\n",
    "z_1_6 = .0548\n",
    "p_22 = z_1_6\n",
    "\n",
    "p_range = z_1-z_1_6\n",
    "n_35 = p_35*90.\n",
    "\n",
    "print p_35,p_22,p_range,n_35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A2) a) 0.1587, b) 0.0548, c) 0.7865, d) 14."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3) A media firm identify that 85% of users of their app are using it to read sports related news articles. Out of a random sample of 100 users, find the probability that a) exactly three quarters of the sample are reading sports articles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00311492186159\n"
     ]
    }
   ],
   "source": [
    "#Combination probability\n",
    "\n",
    "import math\n",
    "def C_n_r(n,r):\n",
    "    N = math.factorial(n)\n",
    "    N_R = math.factorial(n-r)\n",
    "    R = math.factorial(r)\n",
    "    return N/(N_R*R)\n",
    "\n",
    "print C_n_r(100,75)*((0.85)**75.)*((1-0.85)**(100.-75.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A3) 0.00311"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q) What is the probability that the total of two dice will be greater than 7, given that the first die is a 4?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.666666666667\n"
     ]
    }
   ],
   "source": [
    "#Conditional prob.\n",
    "\n",
    "#4,4 - 4,5 - 4,6\n",
    "\n",
    "p1 = 1./6.\n",
    "p1_2 = 4./36.\n",
    "\n",
    "print (p1_2)/p1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A) 2/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4) Calculate the probability being dealt a straight flush (5 consecuative cards of the same suit) off of the top of a dec of cards?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.53907716933e-05\n"
     ]
    }
   ],
   "source": [
    "#Combination probability\n",
    "\n",
    "deck = C_n_r(52,5)\n",
    "SF_combos = 40\n",
    "\n",
    "print 40./deck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A) 1.53907716933e-05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4) Each Pivigo team is composed of 4 people drawn randomly from a pool of 30 women and 60 men. What is the probability that the teams are composed of ; a) two women and two men, b) four men, c) at least 1 women. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.301327885598\n",
      "0.190840994212\n",
      "0.809159005788\n"
     ]
    }
   ],
   "source": [
    "#Combination probability\n",
    "\n",
    "A1 = float(C_n_r(30.,2.))\n",
    "A2 = float(C_n_r(60.,2.))\n",
    "T = float(C_n_r(90.,4.))\n",
    "B1 = float(C_n_r(60.,4.))\n",
    "B2 = float(C_n_r(30.,0.))\n",
    "\n",
    "W1 = float(C_n_r(60.,3.))\n",
    "W2 = float(C_n_r(30.,1.))\n",
    "W5 = float(C_n_r(60.,1.))\n",
    "W6 = float(C_n_r(30.,3.))\n",
    "W7 = float(C_n_r(60.,0.))\n",
    "W8 = float(C_n_r(30.,4.))\n",
    "\n",
    "print A1*A2/T\n",
    "print B1*B2/T\n",
    "print ((W1*W2/T)+(A1*A2/T)+(W5*W6/T)+(W7*W8/T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A4) a) 0.3010, b) 0.1908, c) 0.8092"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5)  A pharmacutical lab is testing a new anti-viral detection drug. They find a false positive rate of 0.2% and a false negative rate of 0.9%. The virus is estimated to be present in 1 in 50,000  people in the population. Calculate a) the instances of the drug failing to detect the virus and b) the instances of the drug incorrectly identifying the virus (hint: in format of 1 per X number of people)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances of virus not detected by the drug. 1: 5600000\n",
      "Instances of drug misclassifying people. 1: 500\n"
     ]
    }
   ],
   "source": [
    "#Classification\n",
    "\n",
    "#Classification rates\n",
    "FPR = 0.002\n",
    "FNR = 0.009\n",
    "#Infection rates\n",
    "Pd = 1./50000.\n",
    "Pn = 1.-Pd\n",
    "\n",
    "#Instances of people with disease AND false negatives\n",
    "FN = Pd*FNR\n",
    "print 'Instances of virus not detected by the drug. 1:',(int(round(1/FN,-5)))\n",
    "#Instances of people without the disease AND false positives\n",
    "FP = Pn*FPR\n",
    "print 'Instances of drug misclassifying people. 1:',(int(round(1/FP,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A5 a) 1:5,600,000, b) 1:500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6) What is the probability of rolling at least one 6 when rolling three dice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42129629629629617"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probability\n",
    "\n",
    "p = 1-((5./6.)**3.)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A6) 0.421"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q)  0.04% of the population was inflected with swine flu. An experimental test has a 99.75% chance of returning a positive result if a subject has the virus. a) Calculate the probability that a randomly selected person tests positive. b) What is the probability that a person is infected, given that they tested positive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002898\n",
      "0.13768115942\n"
     ]
    }
   ],
   "source": [
    "def bayes(P_BA,P_A,P_B):\n",
    "    return (P_BA*P_A)/P_B\n",
    "\n",
    "def P_B(P_A,P_nA,P_B_A,P_B_nA):\n",
    "    return (P_B_A*P_A)+(P_B_nA*P_nA)\n",
    "\n",
    "P_I = 0.0004 #P(A)\n",
    "P_P = 0.9975 #P(B|A)\n",
    "P_nI = 1-P_I #P(-A)\n",
    "P_N = 1-P_P  #P(B|-A)\n",
    "\n",
    "print P_B(P_I,P_nI,P_P,P_N) #P(B)\n",
    "print bayes(P_P,P_I,P_B(P_I,P_nI,P_P,P_N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A) a) 0.0030, b) 0.138"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q) You are playing a game whereby you draw two cards at random from a deck of 52 playing cards with the aim of drawing matching suits. a) If you draw a spade, what is the probability that you will draw a second spade? b) What is the probability drawing two cards of the same suit?\n",
    "\n",
    "A) a) 0.235, b) 0.018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fraction of S2DS students born outside of the UK and currently working in the UK is 7/20. The total fraction born outside of the UK is 2/3. Find the probability that a student is currently working in the UK, given that they were born outside of the UK? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5255255255255254"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.35/0.666"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.53"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8) A fracking company is conducting exploratory drilling in three sites. Each site has 20% probability of proving profitable and each site it independant of the others. If sucessful, the pay off from a single site is $4 million, from two sites it is $3 million (each) and from all three sites it is $2.5 million each (due to excess supply lowering prices). Find the expected payoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1720000000000006"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probability\n",
    "\n",
    "p_1 = 0.2*0.8*0.8\n",
    "p_2 = 0.2*0.2*0.8\n",
    "p_3 = 0.2*0.2*0.2\n",
    "\n",
    "E = (3.*p_1*4.*1.)+(3.*p_2*3.*2)+(1.*p_3*2.5*3.)\n",
    "E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A8) $2.17 million"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9) The leader of the 'British Democratic Party' has a mean public statisfaction rating of -8% with a standard deviation of 12 (assume a normal distribution). Find a) the probability that a person chosen at random will have ranked them greater than +15 and b) ,if the survey size is 1053, calculate the number of individuals whose rankings are considered 'outliers' with +/-3sigma. c) What were the upper and lower bounds of thier scores? Note:statisfaction rankings run from -100 to +100.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.91666666667\n",
      "2\n",
      "28 -44\n"
     ]
    }
   ],
   "source": [
    "#Normal distribution/outliers\n",
    "\n",
    "mean = -8\n",
    "std = 12\n",
    "upp = 15\n",
    "\n",
    "def test(x,u,sigma,n):\n",
    "    Z = (x-u)/(sigma/np.sqrt(n))\n",
    "    return Z\n",
    "\n",
    "t = test(mean,upp,std,1)\n",
    "print t\n",
    "\n",
    "sigma3 = 0.0013*2.\n",
    "N = 1053*sigma3\n",
    "print int(N)\n",
    "print mean+(3*std),mean-(3*std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A9) a) 0.0276 b) 2, c) 28 and -44"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10) A recruiter takes commission from on average 5 placements per month. Find the probability that a) they place at least one person per month,  and b) the probability that they we fail to place anyone in any given week. The manager want's to improve sales and sets a target of 6 or more placements per month. c) calculate the probability of meeting this. (Hint: use Possion's law and assume 4 weeks in a month)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.993262053001\n",
      "0.28650479686\n",
      "0.384039345167\n"
     ]
    }
   ],
   "source": [
    "#Poisson distributions\n",
    "\n",
    "def poisson(mu,x):\n",
    "    return ((np.exp(-mu)*(mu**x))/math.factorial(x))\n",
    "\n",
    "mu = 5.\n",
    "x = 0\n",
    "\n",
    "print 1-poisson(mu,x)\n",
    "\n",
    "mu_w = 5./4.\n",
    "print poisson(mu_w,x)\n",
    "\n",
    "print 1-(poisson(mu,0)+poisson(mu,1)+poisson(mu,2)+poisson(mu,3)+poisson(mu,4)+poisson(mu,5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A10) a) 0.993, b) 0.287, c) 0.384"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q11) The recruitment agency makes contact with 85 needy data scientists every month but only 7% are succesfully placed with a client. A) what is the probability of you sucessfully finding a job with this agency within a month? B) 3 other S2DS graduates join this agency. What is the probability that at least one of you find a job within a month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0126080266562\n",
      "0.243901253388\n"
     ]
    }
   ],
   "source": [
    "#Binomial distribution\n",
    "\n",
    "def binomial(n,r,p):\n",
    "    q = 1-p\n",
    "    return C_n_r(n,r)*(p**r)*(q**(n-r))\n",
    "\n",
    "n = 85.+1.\n",
    "x = 1.\n",
    "p = 0.07\n",
    "\n",
    "print binomial(n,x,p)\n",
    "\n",
    "n = 85.+1.+3.\n",
    "\n",
    "print binomial(n,1,p)+binomial(n,2,p)+binomial(n,3,p)+binomial(n,4,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A11) a) 0.0126, b) 0.244 (???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Q) You are playing the game perudo. They are 6 players and a total of 36 dice in play. The player to your left calls 13 sixes (recall that rolls of one are a wildcard that can equal any other chosen roll). What is the probability that there are exactly 13 sixes in play?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.129147241582\n"
     ]
    }
   ],
   "source": [
    "#Binomial\n",
    "\n",
    "r = 13\n",
    "n = 36\n",
    "p = 1./3.\n",
    "\n",
    "print binomial(n,r,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A). 0.13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Q) You are given the following function:\n",
    "\n",
    "y = log(x)+x^(1/2)-3\n",
    "\n",
    "And an imput variable of x=5. a) calculate y. The standard deviation on x = 0.25. b) calculate the standard deivation on y numerically using a monte-carlo method. c) Compare this answer to that anayltical solution found using the propagation of error.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.845505889934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1060205388094097"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def func(x):\n",
    "    return np.log(x)+(x**(0.5))-3\n",
    "\n",
    "print func(5)\n",
    "\n",
    "x = 5\n",
    "std = 0.25\n",
    "n = 100000\n",
    "\n",
    "MCparts = np.random.normal(x,std,n)\n",
    "\n",
    "MCstd = [func(i) for i in MCparts]\n",
    "\n",
    "np.std(MCstd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A] a) 0.846, b) 0.1060, c) 0.1059"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.96"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def heating(in1,in2,in3):\n",
    "    return 23+(0.056*in1)-(0.42*in2)+(1.5*in3)+(0.015*in2*in3)\n",
    "\n",
    "heating(160,100,15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "from scipy.stats import chisquare\n",
    "from metrics import TS_metrics as metric_class\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "df_predictions = pd.read_csv('Training_predictions.txt', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1)Examine the income of users in the data set 'Training_predictions.txt'. Calculate a) the mean, b) median and c) modal income of a user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Income: mean = 88210.0715, median = 85000.0, mode = 0    78000.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Counting statistics\n",
    "\n",
    "mean = df_predictions['Income'].mean()\n",
    "median = df_predictions['Income'].median()\n",
    "mode = df_predictions['Income'].mode()\n",
    "print 'Income: mean = {}, median = {}, mode = {}'.format(mean,median,mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) 88200 b) 85000 c) 78000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2) Find a) the standard deviation and b) variance of the age population age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Income: std = 37401.3903334 Var = 1398863998.87\n"
     ]
    }
   ],
   "source": [
    "#Counting stats\n",
    "\n",
    "std = df_predictions['Income'].std()\n",
    "var = df_predictions['Income'].var()\n",
    "print 'Income: std = {} Var = {}'.format(std,var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A2) a) 37400 b) 1.4*10^9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3) We hypothesise that users older than 90 years are inhernetly wealthier. We propose a null hypothesis that states that \"the 95% (or greater) confidence that the incomes of 90+ year old users IS consistent with being drawn randomly from the main sample\".\n",
    "\n",
    "\n",
    "Select a subsample of data for users over 90 years old. a) find its mean and b) calculate its 'one sample Z test statistic'. C) find the 95% condfidence interval of the 90 year old sample (hint: the Z score for 95% = 1.96sigma). D) Is the null hypothesis 'True' or 'False'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception KeyboardInterrupt in 'zmq.backend.cython.message.Frame.__dealloc__' ignored\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-188-fb4a3d598342>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf_old\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_predictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_predictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Age'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m90\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mmean_old\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_old\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Income'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_old\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Damian\\Anaconda2\\lib\\site-packages\\pandas\\core\\indexing.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1294\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Damian\\Anaconda2\\lib\\site-packages\\pandas\\core\\indexing.pyc\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1437\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1438\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getbool_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Damian\\Anaconda2\\lib\\site-packages\\pandas\\core\\indexing.pyc\u001b[0m in \u001b[0;36m_getbool_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1304\u001b[0m         \u001b[0minds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1305\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1307\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdetail\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetail\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Damian\\Anaconda2\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indices, axis, convert, is_copy, **kwargs)\u001b[0m\n\u001b[0;32m   1631\u001b[0m         new_data = self._data.take(indices,\n\u001b[0;32m   1632\u001b[0m                                    \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1633\u001b[1;33m                                    convert=True, verify=True)\n\u001b[0m\u001b[0;32m   1634\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1635\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Damian\\Anaconda2\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[0;32m   3709\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3710\u001b[0m         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n\u001b[1;32m-> 3711\u001b[1;33m                                     axis=axis, allow_dups=True)\n\u001b[0m\u001b[0;32m   3712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3713\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Damian\\Anaconda2\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mreindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[0;32m   3595\u001b[0m             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n\u001b[0;32m   3596\u001b[0m                 fill_value if fill_value is not None else blk.fill_value,))\n\u001b[1;32m-> 3597\u001b[1;33m                 for blk in self.blocks]\n\u001b[0m\u001b[0;32m   3598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3599\u001b[0m         \u001b[0mnew_axes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Damian\\Anaconda2\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_tuple)\u001b[0m\n\u001b[0;32m   1006\u001b[0m                 \u001b[0mnew_mgr_locs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1008\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_dtype_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1009\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1010\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Damian\\Anaconda2\\lib\\site-packages\\pandas\\core\\common.pyc\u001b[0m in \u001b[0;36mis_dtype_equal\u001b[1;34m(source, target)\u001b[0m\n\u001b[0;32m   1535\u001b[0m         \u001b[0msource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1536\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1537\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msource\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1538\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Hypothesis testing\n",
    "\n",
    "def test(x,u,sigma,n):\n",
    "    Z = (x-u)/(sigma/np.sqrt(n))\n",
    "    return Z\n",
    "\n",
    "df_old = df_predictions.loc[df_predictions['Age'] > 90 ]\n",
    "mean_old = df_old['Income'].mean()\n",
    "n = len(df_old)\n",
    "Z = test(mean_old,mean,std,n)\n",
    "\n",
    "confidence_95 = 1.96*(std/np.sqrt(n))\n",
    "\n",
    "print 'Old: Mean = {}+/- {}'.format(mean_old,confidence_95)\n",
    "print '95% confidence = +/-1.96 Z-stat = {}'.format(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A3] a) 88500\n",
    "b) 1.32\n",
    "c) 465\n",
    "d) True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Q4] We hypothesise that customers of this company are more wealthy than the national average. We propose a null hypothesis that states that \"there is a 95% or greater confidenece that customers could have been drawn randomly from the national population\".\n",
    "\n",
    "The mean national income is 26500. a) Calculate the \"student's\" t-stat value and b) find the 95% confidence interval of the customer database (hint: the t score for 95%=1.96sigma for inf. degrees of freedom). C) is the null hypothesis true or false?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers: Mean = 26500+/- 51.8356823919\n",
      "95% confidence = +/-1.96 t-stat = -2333.36833931\n"
     ]
    }
   ],
   "source": [
    "#Hypothesis testing\n",
    "\n",
    "mean_nat = 26500\n",
    "n = len(df_predictions)\n",
    "t = test(mean_nat,mean,std,n)\n",
    "confidence_95 = 1.96*(std/np.sqrt(n))\n",
    "\n",
    "print 'Customers: Mean = {}+/- {}'.format(mean_nat,confidence_95)\n",
    "print '95% confidence = +/-1.96 t-stat = {}'.format(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A4] a) -16.5, b) 7331, c) False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5] Taking the standard deviation on the mean national income to be 6000 and assuming the distrbution is gaussian, use the two sample KS-test to compare the distributions of incomes national, and in the company. Find a) the KS-statistic and b) the probablity that each distribution is drawn from the same sample (p-value) - hint: as the population of the uk is 65 million but our data base is only 2 million you will need to normalise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Damian\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:3: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS-stats: D =  0.36  P =  0.0590270263056\n"
     ]
    }
   ],
   "source": [
    "#Hypothesis testing\n",
    "\n",
    "from scipy import stats\n",
    "mu,sigma,n = 26500,6000,65.*(10.**6.)\n",
    "UK_pop = np.random.normal(mu,sigma,n)\n",
    "\n",
    "h,b = np.histogram(df_predictions['Income'],25,normed=True)\n",
    "h_UK,b_UK = np.histogram(UK_pop,25,normed=True)\n",
    "\n",
    "D,P = stats.ks_2samp(h,h_UK)\n",
    "print 'KS-stats: D = ',D,' P = ',P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A5] a) 0.36 b) 5.9%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the 'Modelling_predictions.txt' data set. Find the a) mean square error (MSE) b) mean absolute error (MAE) c) symmetric mean absolute percentage error (SMAPE) d) coefficent of determination (R^2) and e) Chi^2 value of the both the ORF and RRF Customer Value models, compared to the training Customer Values. Which is the best model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) MSE: ORF = 431.779410034 RRF = 6397.97143804\n",
      "b) MAE: ORF = 9.23955673856 RRF = 39.8144096081\n",
      "c)SMAPE: ORF = 10.5349253615 RRF = 43.9369328521\n",
      "d) R2: ORF = 0.9437084819 RRF = 0.165889996982\n",
      "e) Chi2: ORF = 4106432.51725 RRF = 157918924.366\n"
     ]
    }
   ],
   "source": [
    "#Validation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "from scipy.stats import chisquare\n",
    "from metrics import TS_metrics as metric_class\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "df_predictions = pd.read_csv('Training_predictions.txt', sep=';')\n",
    "df_predictions.head()\n",
    "\n",
    "#MSE\n",
    "MSE_ORF = metrics.mean_squared_error(df_predictions.Customer_Value, \n",
    "                                  df_predictions.Predicted_Customer_Value_ORF)\n",
    "MSE_RRF = metrics.mean_squared_error(df_predictions.Customer_Value, \n",
    "                                  df_predictions.Predicted_Customer_Value_RRF)\n",
    "print 'a) MSE: ORF = {} RRF = {}'.format(MSE_ORF,MSE_RRF)\n",
    "#MAE\n",
    "MAE_ORF = metrics.mean_absolute_error(df_predictions.Customer_Value, \n",
    "                                  df_predictions.Predicted_Customer_Value_ORF)\n",
    "MAE_RRF = metrics.mean_absolute_error(df_predictions.Customer_Value, \n",
    "                                  df_predictions.Predicted_Customer_Value_RRF)\n",
    "print 'b) MAE: ORF = {} RRF = {}'.format(MAE_ORF,MAE_RRF)\n",
    "\n",
    "M = metric_class(df_predictions.Customer_Value, \n",
    "            df_predictions.Customer_Value, \n",
    "            df_predictions.Predicted_Customer_Value_ORF)\n",
    "SMAPE_ORF = M.SMAPE()\n",
    "M = metric_class(df_predictions.Customer_Value, \n",
    "            df_predictions.Customer_Value, \n",
    "            df_predictions.Predicted_Customer_Value_RRF)\n",
    "SMAPE_RRF = M.SMAPE()\n",
    "print 'c)SMAPE: ORF = {} RRF = {}'.format(SMAPE_ORF,SMAPE_RRF)\n",
    "R2_ORF = metrics.r2_score(df_predictions.Customer_Value, \n",
    "                                  df_predictions.Predicted_Customer_Value_ORF)       \n",
    "R2_RRF = metrics.r2_score(df_predictions.Customer_Value, \n",
    "                                  df_predictions.Predicted_Customer_Value_RRF)   \n",
    "print 'd) R2: ORF = {} RRF = {}'.format(R2_ORF,R2_RRF)\n",
    "chi_score_ORF, pval_ORF = chisquare(df_predictions.Customer_Value, \n",
    "                                  df_predictions.Predicted_Customer_Value_ORF) \n",
    "chi_score_RRF, pval_RRF = chisquare(df_predictions.Customer_Value, \n",
    "                                  df_predictions.Predicted_Customer_Value_RRF) \n",
    "print 'e) Chi2: ORF = {} RRF = {}'.format(chi_score_ORF,chi_score_RRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "A]\n",
    "\n",
    "a) MSE: ORF = 432 RRF = 6400\n",
    "\n",
    "b) MAE: ORF = 9.24 RRF = 39.8\n",
    "\n",
    "c)SMAPE: ORF = 10.5 RRF = 43.9\n",
    "\n",
    "d) R2: ORF = 0.944 RRF = 0.166\n",
    "\n",
    "e) Chi2: ORF = 4110000 RRF = 158000000\n",
    "\n",
    "ORF is the better model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean =  -0.69263292248\n",
      "Chi_square value:  183.297121963\n",
      "P value:  1.57592553075e-40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.69263292248000075, 183.2971219630123, 1.575925530747776e-40)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = df_predictions.Customer_Value - df_predictions.Predicted_Customer_Value_ORF\n",
    "\n",
    "M = metric_class(res, \n",
    "            df_predictions.Customer_Value, \n",
    "            df_predictions.Predicted_Customer_Value_ORF)\n",
    "M.forecast_accuracy_metric_std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression  modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1] Using the data set 'time_series_1.csv'. Fit a unweighted linear model to data and show that the coefficent of determination (R^2) is 97.4%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97441739231778624"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validation\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import linear_model as lm\n",
    "\n",
    "df = pd.read_csv(\"time_series_1.csv\")\n",
    "\n",
    "#Linear regression model\n",
    "\n",
    "def linear_regression(df):\n",
    "    '''\n",
    "    Plot a weighted linear regression across a give data frame df\n",
    "    '''\n",
    "    x = df.TIME.values\n",
    "    y = df.RATE.values\n",
    "\n",
    "    length = len(x)\n",
    "    x = x.reshape(length, 1)\n",
    "    y = y.reshape(length, 1)\n",
    "\n",
    "    regr = lm.LinearRegression()\n",
    "    regr.fit(x, y)\n",
    "    py = regr.predict(x)\n",
    "    score_val = regr.score(x, y)\n",
    "\n",
    "    return score_val\n",
    "\n",
    "linear_regression(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Q2] Using the data set 'time_series_1.csv'. Fit a weighted linear model to data and show that the coefficent of determination (R^2) is 97.3%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.97285445949486071, array([ 90.94525624]), array([ 0.70574679]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validation\n",
    "\n",
    "def Wlinear_regression(df):\n",
    "    '''\n",
    "    Plot a weighted linear regression across a give data frame df\n",
    "    '''\n",
    "    x = df.TIME.values\n",
    "    y = df.RATE.values\n",
    "    dy = df.ERROR.values\n",
    "\n",
    "    length = len(x)\n",
    "    x = x.reshape(length, 1)\n",
    "    y = y.reshape(length, 1)\n",
    "    Wdy = map(lambda x: x**(-2.),dy)# = dy.reshape(length, 1)\n",
    "\n",
    "    regr = lm.LinearRegression()\n",
    "    regr.fit(x, y,sample_weight=Wdy)\n",
    "    py = regr.predict(x)\n",
    "    score_val = regr.score(x, y,sample_weight=Wdy)\n",
    "    chi_score, pval = chisquare(y, py)\n",
    "    return score_val,chi_score,pval\n",
    "\n",
    "Wlinear_regression(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3] Using the data set 'time_series_2.csv'. Show that a wieghted polynomial model, of order 3, is a better model than a wieghted linear model, using Chi^2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi2: Linear model = [ 328.1583208] Poly Model = 246.47135876\n"
     ]
    }
   ],
   "source": [
    "#Validation\n",
    "\n",
    "df2 = pd.read_csv(\"time_series_2.csv\")\n",
    "\n",
    "def W_Polyfit(df,deg_val):\n",
    "    '''\n",
    "    Plot a weighted linear regression across a give data frame df\n",
    "    '''\n",
    "    x = df.TIME.values\n",
    "    y = df.RATE.values\n",
    "    dy = df.ERROR.values\n",
    "    Wdy = map(lambda x: x**(-2.),dy)# = dy.reshape(length, 1)\n",
    "\n",
    "    polyz = np.polyfit(x,y,deg=deg_val,w=Wdy)\n",
    "    p = np.poly1d(polyz)\n",
    "    xp = np.linspace(min(x), max(x), len(x))\n",
    "    py = p(xp)\n",
    "    \n",
    "    chi_score, pval = chisquare(y, py)\n",
    "    return chi_score,pval\n",
    "\n",
    "score_val,chi_score_LM,pval = Wlinear_regression(df2)\n",
    "chi_score_PM,pval = W_Polyfit(df2,3)\n",
    "print 'Chi2: Linear model = {} Poly Model = {}'.format(chi_score_LM,chi_score_PM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4] Use Chi^2 to find the polynomial order of the model that best fits the data? What one word describes why this value is not suitable for producing a predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree 1 has Chi2 of 426\n",
      "Degree 2 has Chi2 of 245\n",
      "Degree 8 has Chi2 of 241\n",
      "Degree 9 has Chi2 of 229\n"
     ]
    }
   ],
   "source": [
    "#Validation\n",
    "\n",
    "order_list = 10\n",
    "best_Chi2 = 500\n",
    "\n",
    "for i in range(order_list):\n",
    "    chi_score,pval = W_Polyfit(df2,i)\n",
    "    if (chi_score < best_Chi2):\n",
    "        best_Chi2 = chi_score\n",
    "        print \"Degree {} has Chi2 of {}\".format(i,int(best_Chi2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "A4]. 9. Overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
